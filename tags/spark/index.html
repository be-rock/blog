<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Spark | Brock B's Blog</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://be-rock.github.io/blog/tags/spark/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://be-rock.github.io/blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://be-rock.github.io/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://be-rock.github.io/blog/favicon-32x32.png><link rel=apple-touch-icon href=https://be-rock.github.io/blog/apple-touch-icon.png><link rel=mask-icon href=https://be-rock.github.io/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://be-rock.github.io/blog/tags/spark/index.xml><link rel=alternate hreflang=en href=https://be-rock.github.io/blog/tags/spark/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://be-rock.github.io/blog/tags/spark/"><meta property="og:site_name" content="Brock B's Blog"><meta property="og:title" content="Spark"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Spark"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://be-rock.github.io/blog/ accesskey=h title="Brock B's Blog (Alt + H)">Brock B's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://be-rock.github.io/blog/ title=Home><span>Home</span></a></li><li><a href=https://be-rock.github.io/blog/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://be-rock.github.io/blog/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://be-rock.github.io/blog/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Spark</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Apache Spark Streaming - templatized</h2></header><div class=entry-content><p>Summary This is a template / code snippet that can be useful to quickly setup a Spark Streaming Query with a source and sink. The template will not work in all circumstances, such as a foreachBatch sink but is enough to get you started in a quick way, with some examples below on how this could be templatized even more using a markup language like yaml, if so desired.
A Streaming Query template from pyspark.sql import DataFrame from pyspark.sql import functions as f from pyspark.sql.streaming import DataStreamWriter, StreamingQuery NUM = 1 SOURCE = "rate" # delta, kafka, rate TARGET = "noop" # delta, kafka, console, noop QUERY_NAME = f"{SOURCE}-{TARGET}-{NUM}" CHECKPOINT_LOCATION = f"file:/tmp/checkpoint/{QUERY_NAME}" readstream_options = { "rowsPerSecond": "1", # rate # "skipChangeCommits": "true" # delta # "kafka.bootstrap.servers": "localhost:9092", # kafka # "subscribe": "topic1", # kafka # "startingOffsets": "latest", # kafka } trigger_options = { "processingTime": "1 seconds", # "availableNow": "true", } writestream_options = { "checkpointLocation": CHECKPOINT_LOCATION, } def apply_transformations(df: DataFrame) -> DataFrame: return df.withColumn("current_timestamp", f.current_timestamp()) readstream_df: DataFrame = ( spark .readStream .format(SOURCE) .options(**readstream_options) .load() ) transformed_df: DataFrame = apply_transformations(df=readstream_df) datastream_writer: DataStreamWriter = ( transformed_df .writeStream .trigger(**trigger_options) .format(TARGET) .options(**writestream_options) .queryName(QUERY_NAME) ) streaming_query: StreamingQuery = datastream_writer.start() A summary of the above template Dictionaries to manage: stream source options stream sink options trigger options A function to manage all transformations using DataFrame.transform prior to writing to the sink, that can be expanded on A snippet for the DataStreamWriter And finally, a call to .start() to return a StreamingQuery Note that this would need to change to toTable() if writing to a table sink such as delta or iceberg. Further templatizing this code You may wnat to codify this further into a markup language like yaml and then make the configuration strongly-typed using pydantic. Here’s an example of what that might look like:
...</p></div><footer class=entry-footer><span title='2025-10-12 20:21:51 -0500 -0500'>October 12, 2025</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;320 words</footer><a class=entry-link aria-label="post link to Apache Spark Streaming - templatized" href=https://be-rock.github.io/blog/posts/exploring-apache-spark-stream-sources-and-sinks/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Streaming with Bufstream, Protobuf, and Spark</h2></header><div class=entry-content><p>Summary Bufstream is said to be a drop-in replacement for Kafka via a simple Go-based binary Bufstream also standardizes on Protocol Buffers as the serialization format for messaging and integrates well with Lakehouses by writing directly to an Iceberg sink What is the point? I often work with streaming and Kafka with Apache Spark. Setting up and managing a Kafka cluster can be cumbersome so having a quick, easy, standardized, and leightweight way to run Kafka is appealing. This blog attempts to test the claims of Buf - the company behind: Bufstream - the “drop-in replacement for Kafka” BSR - the Buf Schema Registry which implements the Confluent Schema Registry API buf CLI - a simple way to develop and manage Protobuf Note that the buf CLI will be referenced in this blog, but less of a focus.
...</p></div><footer class=entry-footer><span title='2025-08-09 22:29:16 -0500 -0500'>August 9, 2025</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1435 words</footer><a class=entry-link aria-label="post link to Streaming with Bufstream, Protobuf, and Spark" href=https://be-rock.github.io/blog/posts/kafka-protobuf-and-bufstream/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Using a Container to run PySpark Unit Tests</h2></header><div class=entry-content><p>Summary Running PySpark unit tests in a Container can make for a repeatable, portable way to unit test your code This simple library can be used as a template to create a repeatable set of Pyspark tests for both reference and understanding Why, just why? Hopefully you do not need to be convinced of the value of unit testing; there is really no shortage of content on this topic. If we can agree on that, what I have found in my day-to-day is that I am often in the Spark shell trying to evaluate functions, generate explain plans, and trying to confirm my understanding of internals.
...</p></div><footer class=entry-footer><span title='2025-07-12 12:58:15 -0500 -0500'>July 12, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;761 words</footer><a class=entry-link aria-label="post link to Using a Container to run PySpark Unit Tests" href=https://be-rock.github.io/blog/posts/pyspark-container-unit-tests/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Building a Pyspark Custom Data Sources for DuckDB</h2></header><div class=entry-content><p>Summary Apache Spark 4.0 and Databricks 15.2 supports custom Pyspark Data Sources A custom data source allows you to connect to a source system that that Spark may not currently have support for PySpark Custom Data Sources - an Overview Starting with Apache Spark 4.0 and Databricks 15.2, PySpark supports custom data sources.
So what are PySpark Custom Data Sources?
Custom data sources allow you to define a source format other than the default built-in formats such as csv, json, and parquet. There are many other supported formats such as Delta and Iceberg, but if there is no community or commercial support offered for the data source of interest, you can extend and inherit some builtin PySpark classes and roll your own. One common example of this may be calling a REST endpoint.
...</p></div><footer class=entry-footer><span title='2025-06-14 23:51:42 -0500 -0500'>June 14, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;658 words</footer><a class=entry-link aria-label="post link to Building a Pyspark Custom Data Sources for DuckDB" href=https://be-rock.github.io/blog/posts/pyspark-custom-datasource-duckdb/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://be-rock.github.io/blog/>Brock B's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>