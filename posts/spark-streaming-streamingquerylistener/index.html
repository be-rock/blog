<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Using the StreamingQueryListener with Spark Streaming | Brock's Blog on Data|DevOps|Cloud</title><meta name=keywords content="spark,streaming,streaming query listener"><meta name=description content='Summary
This is an example of how to setup a Spark  StreamingQueryListener that writes to some sample targets such as json and Postgres.
Setup
Streaming Query
from pyspark.sql import DataFrame
from pyspark.sql import functions as f
from pyspark.sql.streaming import DataStreamWriter, StreamingQuery

NUM = 1
SOURCE = "rate"
TARGET = "noop"
QUERY_NAME = f"{SOURCE}-{TARGET}-{NUM}"
CHECKPOINT_LOCATION = f"file:/tmp/checkpoint/{QUERY_NAME}"

readstream_options = {
    "rowsPerSecond": "1",
}

trigger_options = {
    "processingTime": "10 seconds",
}

writestream_options = {
    "checkpointLocation": CHECKPOINT_LOCATION,
}

readstream_df: DataFrame = (
    spark
    .readStream
    .format(SOURCE)
    .options(**readstream_options)
    .load()
)

datastream_writer: DataStreamWriter = (
    readstream_df
    .writeStream
    .trigger(**trigger_options)
    .format(TARGET)
    .options(**writestream_options)
    .queryName(QUERY_NAME)
)

streaming_query: StreamingQuery = datastream_writer.start()
Streaming Query Listener - json to stdout
import datetime
import json

from pyspark.sql.streaming.listener import (
    QueryIdleEvent,
    QueryProgressEvent,
    QueryStartedEvent,
    QueryTerminatedEvent,
    StreamingQueryListener,
)

class StreamingQueryListenerJson(StreamingQueryListener):

    def onQueryStarted(self, event: QueryStartedEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryStarted",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query started"
        }
        print(payload)


    def onQueryProgress(self, event: QueryProgressEvent) -> None:
        json_data = json.loads(event.progress.json)
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryProgress",
            "id": json_data.get("id"),
            "name": json_data.get("name"),
            "runId": json_data.get("runId"),
            "message": json.dumps(json_data)
        }
        print(payload)

    def onQueryIdle(self, event: QueryIdleEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryIdle",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query is idle"
        }
        print(payload)

    def onQueryTerminated(self, event: QueryTerminatedEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryIdle",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query is terminated"
        }
        print(payload)

spark.streams.addListener(StreamingQueryListenerJson())
Streaming Query Listener - json to a file
import datetime

from pyspark.sql.streaming.listener import (
    QueryIdleEvent,
    QueryProgressEvent,
    QueryStartedEvent,
    QueryTerminatedEvent,
    StreamingQueryListener,
)

class StreamingQueryListenerJson(StreamingQueryListener):
    def __init__(self) -> None:
        self.f = open("/tmp/f.json", "w")

    def onQueryStarted(self, event: QueryStartedEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryStarted",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query started"
        }
        self.f.write(json.dumps(payload))


    def onQueryProgress(self, event: QueryProgressEvent) -> None:
        json_data = json.loads(event.progress.json)
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryProgress",
            "id": json_data.get("id"),
            "name": json_data.get("name"),
            "runId": json_data.get("runId"),
            "message": json.dumps(json_data)
        }
        self.f.write(json.dumps(payload))

    def onQueryIdle(self, event: QueryIdleEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryIdle",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query is idle"
        }
        self.f.write(json.dumps(payload))

    def onQueryTerminated(self, event: QueryTerminatedEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryIdle",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query is terminated"
        }
        self.f.write(json.dumps(payload))
        self.f.close()

spark.streams.addListener(StreamingQueryListenerJson())
Streaming Query Listener - Sqlite
Sqlite is not multi-threaded so we can experience failures with concurrent writes. One way to prevent this issue from happening, is to append the StreamingQueryListener events to append to a Python queue.Queue() instead of directly to the database, so that all writes can be managed by a single thread.'><meta name=author content><link rel=canonical href=https://be-rock.github.io/blog/posts/spark-streaming-streamingquerylistener/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://be-rock.github.io/blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://be-rock.github.io/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://be-rock.github.io/blog/favicon-32x32.png><link rel=apple-touch-icon href=https://be-rock.github.io/blog/apple-touch-icon.png><link rel=mask-icon href=https://be-rock.github.io/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://be-rock.github.io/blog/posts/spark-streaming-streamingquerylistener/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://be-rock.github.io/blog/posts/spark-streaming-streamingquerylistener/"><meta property="og:site_name" content="Brock's Blog on Data|DevOps|Cloud"><meta property="og:title" content="Using the StreamingQueryListener with Spark Streaming"><meta property="og:description" content='Summary This is an example of how to setup a Spark StreamingQueryListener that writes to some sample targets such as json and Postgres.
Setup Streaming Query from pyspark.sql import DataFrame from pyspark.sql import functions as f from pyspark.sql.streaming import DataStreamWriter, StreamingQuery NUM = 1 SOURCE = "rate" TARGET = "noop" QUERY_NAME = f"{SOURCE}-{TARGET}-{NUM}" CHECKPOINT_LOCATION = f"file:/tmp/checkpoint/{QUERY_NAME}" readstream_options = { "rowsPerSecond": "1", } trigger_options = { "processingTime": "10 seconds", } writestream_options = { "checkpointLocation": CHECKPOINT_LOCATION, } readstream_df: DataFrame = ( spark .readStream .format(SOURCE) .options(**readstream_options) .load() ) datastream_writer: DataStreamWriter = ( readstream_df .writeStream .trigger(**trigger_options) .format(TARGET) .options(**writestream_options) .queryName(QUERY_NAME) ) streaming_query: StreamingQuery = datastream_writer.start() Streaming Query Listener - json to stdout import datetime import json from pyspark.sql.streaming.listener import ( QueryIdleEvent, QueryProgressEvent, QueryStartedEvent, QueryTerminatedEvent, StreamingQueryListener, ) class StreamingQueryListenerJson(StreamingQueryListener): def onQueryStarted(self, event: QueryStartedEvent) -> None: payload = { "time": datetime.datetime.now().isoformat(), "event": "onQueryStarted", "id": event.id, "name": event.name, "runId": event.runId, "message": "query started" } print(payload) def onQueryProgress(self, event: QueryProgressEvent) -> None: json_data = json.loads(event.progress.json) payload = { "time": datetime.datetime.now().isoformat(), "event": "onQueryProgress", "id": json_data.get("id"), "name": json_data.get("name"), "runId": json_data.get("runId"), "message": json.dumps(json_data) } print(payload) def onQueryIdle(self, event: QueryIdleEvent) -> None: payload = { "time": datetime.datetime.now().isoformat(), "event": "onQueryIdle", "id": event.id, "name": event.name, "runId": event.runId, "message": "query is idle" } print(payload) def onQueryTerminated(self, event: QueryTerminatedEvent) -> None: payload = { "time": datetime.datetime.now().isoformat(), "event": "onQueryIdle", "id": event.id, "name": event.name, "runId": event.runId, "message": "query is terminated" } print(payload) spark.streams.addListener(StreamingQueryListenerJson()) Streaming Query Listener - json to a file import datetime from pyspark.sql.streaming.listener import ( QueryIdleEvent, QueryProgressEvent, QueryStartedEvent, QueryTerminatedEvent, StreamingQueryListener, ) class StreamingQueryListenerJson(StreamingQueryListener): def __init__(self) -> None: self.f = open("/tmp/f.json", "w") def onQueryStarted(self, event: QueryStartedEvent) -> None: payload = { "time": datetime.datetime.now().isoformat(), "event": "onQueryStarted", "id": event.id, "name": event.name, "runId": event.runId, "message": "query started" } self.f.write(json.dumps(payload)) def onQueryProgress(self, event: QueryProgressEvent) -> None: json_data = json.loads(event.progress.json) payload = { "time": datetime.datetime.now().isoformat(), "event": "onQueryProgress", "id": json_data.get("id"), "name": json_data.get("name"), "runId": json_data.get("runId"), "message": json.dumps(json_data) } self.f.write(json.dumps(payload)) def onQueryIdle(self, event: QueryIdleEvent) -> None: payload = { "time": datetime.datetime.now().isoformat(), "event": "onQueryIdle", "id": event.id, "name": event.name, "runId": event.runId, "message": "query is idle" } self.f.write(json.dumps(payload)) def onQueryTerminated(self, event: QueryTerminatedEvent) -> None: payload = { "time": datetime.datetime.now().isoformat(), "event": "onQueryIdle", "id": event.id, "name": event.name, "runId": event.runId, "message": "query is terminated" } self.f.write(json.dumps(payload)) self.f.close() spark.streams.addListener(StreamingQueryListenerJson()) Streaming Query Listener - Sqlite Sqlite is not multi-threaded so we can experience failures with concurrent writes. One way to prevent this issue from happening, is to append the StreamingQueryListener events to append to a Python queue.Queue() instead of directly to the database, so that all writes can be managed by a single thread.'><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-13T20:08:27-05:00"><meta property="article:modified_time" content="2025-10-13T20:08:27-05:00"><meta property="article:tag" content="Spark"><meta property="article:tag" content="Streaming"><meta property="article:tag" content="Streaming Query Listener"><meta name=twitter:card content="summary"><meta name=twitter:title content="Using the StreamingQueryListener with Spark Streaming"><meta name=twitter:description content='Summary
This is an example of how to setup a Spark  StreamingQueryListener that writes to some sample targets such as json and Postgres.
Setup
Streaming Query
from pyspark.sql import DataFrame
from pyspark.sql import functions as f
from pyspark.sql.streaming import DataStreamWriter, StreamingQuery

NUM = 1
SOURCE = "rate"
TARGET = "noop"
QUERY_NAME = f"{SOURCE}-{TARGET}-{NUM}"
CHECKPOINT_LOCATION = f"file:/tmp/checkpoint/{QUERY_NAME}"

readstream_options = {
    "rowsPerSecond": "1",
}

trigger_options = {
    "processingTime": "10 seconds",
}

writestream_options = {
    "checkpointLocation": CHECKPOINT_LOCATION,
}

readstream_df: DataFrame = (
    spark
    .readStream
    .format(SOURCE)
    .options(**readstream_options)
    .load()
)

datastream_writer: DataStreamWriter = (
    readstream_df
    .writeStream
    .trigger(**trigger_options)
    .format(TARGET)
    .options(**writestream_options)
    .queryName(QUERY_NAME)
)

streaming_query: StreamingQuery = datastream_writer.start()
Streaming Query Listener - json to stdout
import datetime
import json

from pyspark.sql.streaming.listener import (
    QueryIdleEvent,
    QueryProgressEvent,
    QueryStartedEvent,
    QueryTerminatedEvent,
    StreamingQueryListener,
)

class StreamingQueryListenerJson(StreamingQueryListener):

    def onQueryStarted(self, event: QueryStartedEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryStarted",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query started"
        }
        print(payload)


    def onQueryProgress(self, event: QueryProgressEvent) -> None:
        json_data = json.loads(event.progress.json)
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryProgress",
            "id": json_data.get("id"),
            "name": json_data.get("name"),
            "runId": json_data.get("runId"),
            "message": json.dumps(json_data)
        }
        print(payload)

    def onQueryIdle(self, event: QueryIdleEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryIdle",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query is idle"
        }
        print(payload)

    def onQueryTerminated(self, event: QueryTerminatedEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryIdle",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query is terminated"
        }
        print(payload)

spark.streams.addListener(StreamingQueryListenerJson())
Streaming Query Listener - json to a file
import datetime

from pyspark.sql.streaming.listener import (
    QueryIdleEvent,
    QueryProgressEvent,
    QueryStartedEvent,
    QueryTerminatedEvent,
    StreamingQueryListener,
)

class StreamingQueryListenerJson(StreamingQueryListener):
    def __init__(self) -> None:
        self.f = open("/tmp/f.json", "w")

    def onQueryStarted(self, event: QueryStartedEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryStarted",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query started"
        }
        self.f.write(json.dumps(payload))


    def onQueryProgress(self, event: QueryProgressEvent) -> None:
        json_data = json.loads(event.progress.json)
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryProgress",
            "id": json_data.get("id"),
            "name": json_data.get("name"),
            "runId": json_data.get("runId"),
            "message": json.dumps(json_data)
        }
        self.f.write(json.dumps(payload))

    def onQueryIdle(self, event: QueryIdleEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryIdle",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query is idle"
        }
        self.f.write(json.dumps(payload))

    def onQueryTerminated(self, event: QueryTerminatedEvent) -> None:
        payload = {
            "time": datetime.datetime.now().isoformat(),
            "event": "onQueryIdle",
            "id": event.id,
            "name": event.name,
            "runId": event.runId,
            "message": "query is terminated"
        }
        self.f.write(json.dumps(payload))
        self.f.close()

spark.streams.addListener(StreamingQueryListenerJson())
Streaming Query Listener - Sqlite
Sqlite is not multi-threaded so we can experience failures with concurrent writes. One way to prevent this issue from happening, is to append the StreamingQueryListener events to append to a Python queue.Queue() instead of directly to the database, so that all writes can be managed by a single thread.'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://be-rock.github.io/blog/posts/"},{"@type":"ListItem","position":2,"name":"Using the StreamingQueryListener with Spark Streaming","item":"https://be-rock.github.io/blog/posts/spark-streaming-streamingquerylistener/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Using the StreamingQueryListener with Spark Streaming","name":"Using the StreamingQueryListener with Spark Streaming","description":"Summary This is an example of how to setup a Spark StreamingQueryListener that writes to some sample targets such as json and Postgres.\nSetup Streaming Query from pyspark.sql import DataFrame from pyspark.sql import functions as f from pyspark.sql.streaming import DataStreamWriter, StreamingQuery NUM = 1 SOURCE = \u0026#34;rate\u0026#34; TARGET = \u0026#34;noop\u0026#34; QUERY_NAME = f\u0026#34;{SOURCE}-{TARGET}-{NUM}\u0026#34; CHECKPOINT_LOCATION = f\u0026#34;file:/tmp/checkpoint/{QUERY_NAME}\u0026#34; readstream_options = { \u0026#34;rowsPerSecond\u0026#34;: \u0026#34;1\u0026#34;, } trigger_options = { \u0026#34;processingTime\u0026#34;: \u0026#34;10 seconds\u0026#34;, } writestream_options = { \u0026#34;checkpointLocation\u0026#34;: CHECKPOINT_LOCATION, } readstream_df: DataFrame = ( spark .readStream .format(SOURCE) .options(**readstream_options) .load() ) datastream_writer: DataStreamWriter = ( readstream_df .writeStream .trigger(**trigger_options) .format(TARGET) .options(**writestream_options) .queryName(QUERY_NAME) ) streaming_query: StreamingQuery = datastream_writer.start() Streaming Query Listener - json to stdout import datetime import json from pyspark.sql.streaming.listener import ( QueryIdleEvent, QueryProgressEvent, QueryStartedEvent, QueryTerminatedEvent, StreamingQueryListener, ) class StreamingQueryListenerJson(StreamingQueryListener): def onQueryStarted(self, event: QueryStartedEvent) -\u0026gt; None: payload = { \u0026#34;time\u0026#34;: datetime.datetime.now().isoformat(), \u0026#34;event\u0026#34;: \u0026#34;onQueryStarted\u0026#34;, \u0026#34;id\u0026#34;: event.id, \u0026#34;name\u0026#34;: event.name, \u0026#34;runId\u0026#34;: event.runId, \u0026#34;message\u0026#34;: \u0026#34;query started\u0026#34; } print(payload) def onQueryProgress(self, event: QueryProgressEvent) -\u0026gt; None: json_data = json.loads(event.progress.json) payload = { \u0026#34;time\u0026#34;: datetime.datetime.now().isoformat(), \u0026#34;event\u0026#34;: \u0026#34;onQueryProgress\u0026#34;, \u0026#34;id\u0026#34;: json_data.get(\u0026#34;id\u0026#34;), \u0026#34;name\u0026#34;: json_data.get(\u0026#34;name\u0026#34;), \u0026#34;runId\u0026#34;: json_data.get(\u0026#34;runId\u0026#34;), \u0026#34;message\u0026#34;: json.dumps(json_data) } print(payload) def onQueryIdle(self, event: QueryIdleEvent) -\u0026gt; None: payload = { \u0026#34;time\u0026#34;: datetime.datetime.now().isoformat(), \u0026#34;event\u0026#34;: \u0026#34;onQueryIdle\u0026#34;, \u0026#34;id\u0026#34;: event.id, \u0026#34;name\u0026#34;: event.name, \u0026#34;runId\u0026#34;: event.runId, \u0026#34;message\u0026#34;: \u0026#34;query is idle\u0026#34; } print(payload) def onQueryTerminated(self, event: QueryTerminatedEvent) -\u0026gt; None: payload = { \u0026#34;time\u0026#34;: datetime.datetime.now().isoformat(), \u0026#34;event\u0026#34;: \u0026#34;onQueryIdle\u0026#34;, \u0026#34;id\u0026#34;: event.id, \u0026#34;name\u0026#34;: event.name, \u0026#34;runId\u0026#34;: event.runId, \u0026#34;message\u0026#34;: \u0026#34;query is terminated\u0026#34; } print(payload) spark.streams.addListener(StreamingQueryListenerJson()) Streaming Query Listener - json to a file import datetime from pyspark.sql.streaming.listener import ( QueryIdleEvent, QueryProgressEvent, QueryStartedEvent, QueryTerminatedEvent, StreamingQueryListener, ) class StreamingQueryListenerJson(StreamingQueryListener): def __init__(self) -\u0026gt; None: self.f = open(\u0026#34;/tmp/f.json\u0026#34;, \u0026#34;w\u0026#34;) def onQueryStarted(self, event: QueryStartedEvent) -\u0026gt; None: payload = { \u0026#34;time\u0026#34;: datetime.datetime.now().isoformat(), \u0026#34;event\u0026#34;: \u0026#34;onQueryStarted\u0026#34;, \u0026#34;id\u0026#34;: event.id, \u0026#34;name\u0026#34;: event.name, \u0026#34;runId\u0026#34;: event.runId, \u0026#34;message\u0026#34;: \u0026#34;query started\u0026#34; } self.f.write(json.dumps(payload)) def onQueryProgress(self, event: QueryProgressEvent) -\u0026gt; None: json_data = json.loads(event.progress.json) payload = { \u0026#34;time\u0026#34;: datetime.datetime.now().isoformat(), \u0026#34;event\u0026#34;: \u0026#34;onQueryProgress\u0026#34;, \u0026#34;id\u0026#34;: json_data.get(\u0026#34;id\u0026#34;), \u0026#34;name\u0026#34;: json_data.get(\u0026#34;name\u0026#34;), \u0026#34;runId\u0026#34;: json_data.get(\u0026#34;runId\u0026#34;), \u0026#34;message\u0026#34;: json.dumps(json_data) } self.f.write(json.dumps(payload)) def onQueryIdle(self, event: QueryIdleEvent) -\u0026gt; None: payload = { \u0026#34;time\u0026#34;: datetime.datetime.now().isoformat(), \u0026#34;event\u0026#34;: \u0026#34;onQueryIdle\u0026#34;, \u0026#34;id\u0026#34;: event.id, \u0026#34;name\u0026#34;: event.name, \u0026#34;runId\u0026#34;: event.runId, \u0026#34;message\u0026#34;: \u0026#34;query is idle\u0026#34; } self.f.write(json.dumps(payload)) def onQueryTerminated(self, event: QueryTerminatedEvent) -\u0026gt; None: payload = { \u0026#34;time\u0026#34;: datetime.datetime.now().isoformat(), \u0026#34;event\u0026#34;: \u0026#34;onQueryIdle\u0026#34;, \u0026#34;id\u0026#34;: event.id, \u0026#34;name\u0026#34;: event.name, \u0026#34;runId\u0026#34;: event.runId, \u0026#34;message\u0026#34;: \u0026#34;query is terminated\u0026#34; } self.f.write(json.dumps(payload)) self.f.close() spark.streams.addListener(StreamingQueryListenerJson()) Streaming Query Listener - Sqlite Sqlite is not multi-threaded so we can experience failures with concurrent writes. One way to prevent this issue from happening, is to append the StreamingQueryListener events to append to a Python queue.Queue() instead of directly to the database, so that all writes can be managed by a single thread.\n","keywords":["spark","streaming","streaming query listener"],"articleBody":"Summary This is an example of how to setup a Spark StreamingQueryListener that writes to some sample targets such as json and Postgres.\nSetup Streaming Query from pyspark.sql import DataFrame from pyspark.sql import functions as f from pyspark.sql.streaming import DataStreamWriter, StreamingQuery NUM = 1 SOURCE = \"rate\" TARGET = \"noop\" QUERY_NAME = f\"{SOURCE}-{TARGET}-{NUM}\" CHECKPOINT_LOCATION = f\"file:/tmp/checkpoint/{QUERY_NAME}\" readstream_options = { \"rowsPerSecond\": \"1\", } trigger_options = { \"processingTime\": \"10 seconds\", } writestream_options = { \"checkpointLocation\": CHECKPOINT_LOCATION, } readstream_df: DataFrame = ( spark .readStream .format(SOURCE) .options(**readstream_options) .load() ) datastream_writer: DataStreamWriter = ( readstream_df .writeStream .trigger(**trigger_options) .format(TARGET) .options(**writestream_options) .queryName(QUERY_NAME) ) streaming_query: StreamingQuery = datastream_writer.start() Streaming Query Listener - json to stdout import datetime import json from pyspark.sql.streaming.listener import ( QueryIdleEvent, QueryProgressEvent, QueryStartedEvent, QueryTerminatedEvent, StreamingQueryListener, ) class StreamingQueryListenerJson(StreamingQueryListener): def onQueryStarted(self, event: QueryStartedEvent) -\u003e None: payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryStarted\", \"id\": event.id, \"name\": event.name, \"runId\": event.runId, \"message\": \"query started\" } print(payload) def onQueryProgress(self, event: QueryProgressEvent) -\u003e None: json_data = json.loads(event.progress.json) payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryProgress\", \"id\": json_data.get(\"id\"), \"name\": json_data.get(\"name\"), \"runId\": json_data.get(\"runId\"), \"message\": json.dumps(json_data) } print(payload) def onQueryIdle(self, event: QueryIdleEvent) -\u003e None: payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryIdle\", \"id\": event.id, \"name\": event.name, \"runId\": event.runId, \"message\": \"query is idle\" } print(payload) def onQueryTerminated(self, event: QueryTerminatedEvent) -\u003e None: payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryIdle\", \"id\": event.id, \"name\": event.name, \"runId\": event.runId, \"message\": \"query is terminated\" } print(payload) spark.streams.addListener(StreamingQueryListenerJson()) Streaming Query Listener - json to a file import datetime from pyspark.sql.streaming.listener import ( QueryIdleEvent, QueryProgressEvent, QueryStartedEvent, QueryTerminatedEvent, StreamingQueryListener, ) class StreamingQueryListenerJson(StreamingQueryListener): def __init__(self) -\u003e None: self.f = open(\"/tmp/f.json\", \"w\") def onQueryStarted(self, event: QueryStartedEvent) -\u003e None: payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryStarted\", \"id\": event.id, \"name\": event.name, \"runId\": event.runId, \"message\": \"query started\" } self.f.write(json.dumps(payload)) def onQueryProgress(self, event: QueryProgressEvent) -\u003e None: json_data = json.loads(event.progress.json) payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryProgress\", \"id\": json_data.get(\"id\"), \"name\": json_data.get(\"name\"), \"runId\": json_data.get(\"runId\"), \"message\": json.dumps(json_data) } self.f.write(json.dumps(payload)) def onQueryIdle(self, event: QueryIdleEvent) -\u003e None: payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryIdle\", \"id\": event.id, \"name\": event.name, \"runId\": event.runId, \"message\": \"query is idle\" } self.f.write(json.dumps(payload)) def onQueryTerminated(self, event: QueryTerminatedEvent) -\u003e None: payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryIdle\", \"id\": event.id, \"name\": event.name, \"runId\": event.runId, \"message\": \"query is terminated\" } self.f.write(json.dumps(payload)) self.f.close() spark.streams.addListener(StreamingQueryListenerJson()) Streaming Query Listener - Sqlite Sqlite is not multi-threaded so we can experience failures with concurrent writes. One way to prevent this issue from happening, is to append the StreamingQueryListener events to append to a Python queue.Queue() instead of directly to the database, so that all writes can be managed by a single thread.\nfrom concurrent.futures import ThreadPoolExecutor import datetime import json import queue import sqlite3 import time from pyspark.sql.streaming.listener import ( QueryIdleEvent, QueryProgressEvent, QueryStartedEvent, QueryTerminatedEvent, StreamingQueryListener, ) DB_PATH = \"file:/tmp/f.db\" class StreamingQueryListenerSqlite(StreamingQueryListener): def __init__(self, db_path: str = DB_PATH) -\u003e None: self.queue = queue.Queue() self.db_path = db_path self._executor = ThreadPoolExecutor(max_workers=1) self._database_setup() self._insert_statement = \"\"\" INSERT INTO data (time, event, id, name, runId, message) values (?, ?, ?, ?, ?, ?) \"\"\" self._executor.submit(self._queue_worker) def _create_connection(self) -\u003e sqlite3.Connection: return sqlite3.connect(self.db_path) def _create_cursor(self, connection: sqlite3.Connection) -\u003e sqlite3.Cursor: return connection.cursor() def _database_setup(self) -\u003e None: conn = self._create_connection() cur = self._create_cursor(connection=conn) cur.execute(\"\"\" CREATE TABLE IF NOT EXISTS data ( time TIMESTAMP NOT NULL, event TEXT NOT NULL, id TEXT NOT NULL, name TEXT NOT NULL, runId TEXT NOT NULL, message TEXT NOT NULL ) \"\"\") conn.commit() conn.close() def onQueryStarted(self, event: QueryStartedEvent) -\u003e None: payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryStarted\", \"id\": event.id, \"name\": event.name, \"runId\": event.runId, \"message\": \"query started\", } self.queue.put(json.dumps(payload)) def onQueryProgress(self, event: QueryProgressEvent) -\u003e None: json_data = json.loads(event.progress.json) payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryProgress\", \"id\": json_data.get(\"id\"), \"name\": json_data.get(\"name\"), \"runId\": json_data.get(\"runId\"), \"message\": json.dumps(json_data), } self.queue.put(json.dumps(payload)) def onQueryIdle(self, event: QueryIdleEvent) -\u003e None: payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryIdle\", \"id\": event.id, \"name\": event.name, \"runId\": event.runId, \"message\": \"query is idle\", } self.queue.put(json.dumps(payload)) def onQueryTerminated(self, event: QueryTerminatedEvent) -\u003e None: payload = { \"time\": datetime.datetime.now().isoformat(), \"event\": \"onQueryIdle\", \"id\": event.id, \"name\": event.name, \"runId\": event.runId, \"message\": \"query is terminated\", } self.queue.put(json.dumps(payload)) self._conn.close() def _queue_worker(self) -\u003e None: \"\"\"Background worker that processes items from the queue and inserts them into the database. Runs continuously in a separate thread, polling the queue every second for new items. When an item is found, calls _insert_item_to_db to persist it. The worker will continue running until the thread is terminated or the program exits. If the queue is empty, it will wait for 1 second before checking again. \"\"\" self._conn = self._create_connection() self._cursor = self._create_cursor(connection=self._conn) while True: try: item: str = self.queue.get(timeout=1) self._insert_item_to_db( item=item, connection=self._conn, cursor=self._cursor ) except queue.Empty: continue def _insert_item_to_db( self, item: str, connection: sqlite3.Connection, cursor: sqlite3.Cursor ) -\u003e None: print(f\"inserting item {item} to db ...\") data = json.loads(item) cursor.execute( self._insert_statement, ( data.get(\"time\"), data.get(\"event\"), data.get(\"id\"), data.get(\"name\"), data.get(\"runId\"), data.get(\"message\"), ), ) connection.commit() spark.streams.addListener(StreamingQueryListenerSqlite()) Streaming Query Listener - other options Other possible targets for the StreamingQueryListener events could include:\nan OLTP database like Postgres DuckDB (although similar concurrency issues as experienced with Sqlite may occur) OpenTelemetry AWS CloudWatch Datadog / Splunk / Prometheus ","wordCount":"804","inLanguage":"en","datePublished":"2025-10-13T20:08:27-05:00","dateModified":"2025-10-13T20:08:27-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://be-rock.github.io/blog/posts/spark-streaming-streamingquerylistener/"},"publisher":{"@type":"Organization","name":"Brock's Blog on Data|DevOps|Cloud","logo":{"@type":"ImageObject","url":"https://be-rock.github.io/blog/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://be-rock.github.io/blog/ accesskey=h title="Brock's Blog on Data|DevOps|Cloud (Alt + H)">Brock's Blog on Data|DevOps|Cloud</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://be-rock.github.io/blog/ title=Home><span>Home</span></a></li><li><a href=https://be-rock.github.io/blog/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://be-rock.github.io/blog/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://be-rock.github.io/blog/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Using the StreamingQueryListener with Spark Streaming</h1><div class=post-meta><span title='2025-10-13 20:08:27 -0500 -0500'>October 13, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;804 words</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#summary aria-label=Summary>Summary</a></li><li><a href=#setup aria-label=Setup>Setup</a><ul><li><a href=#streaming-query aria-label="Streaming Query">Streaming Query</a></li><li><a href=#streaming-query-listener---json-to-stdout aria-label="Streaming Query Listener - json to stdout">Streaming Query Listener - json to stdout</a></li><li><a href=#streaming-query-listener---json-to-a-file aria-label="Streaming Query Listener - json to a file">Streaming Query Listener - json to a file</a></li><li><a href=#streaming-query-listener---sqlite aria-label="Streaming Query Listener - Sqlite">Streaming Query Listener - Sqlite</a></li><li><a href=#streaming-query-listener---other-options aria-label="Streaming Query Listener - other options">Streaming Query Listener - other options</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>This is an example of how to setup a Spark <a href=https://spark.apache.org/docs/latest/api/python/reference/pyspark.ss/api/pyspark.sql.streaming.StreamingQueryListener.html><code>StreamingQueryListener</code></a> that writes to some sample targets such as <code>json</code> and <code>Postgres</code>.</p><h2 id=setup>Setup<a hidden class=anchor aria-hidden=true href=#setup>#</a></h2><h3 id=streaming-query>Streaming Query<a hidden class=anchor aria-hidden=true href=#streaming-query>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql <span style=color:#f92672>import</span> DataFrame
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql <span style=color:#f92672>import</span> functions <span style=color:#66d9ef>as</span> f
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql.streaming <span style=color:#f92672>import</span> DataStreamWriter, StreamingQuery
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NUM <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>SOURCE <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;rate&#34;</span>
</span></span><span style=display:flex><span>TARGET <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;noop&#34;</span>
</span></span><span style=display:flex><span>QUERY_NAME <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>SOURCE<span style=color:#e6db74>}</span><span style=color:#e6db74>-</span><span style=color:#e6db74>{</span>TARGET<span style=color:#e6db74>}</span><span style=color:#e6db74>-</span><span style=color:#e6db74>{</span>NUM<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>CHECKPOINT_LOCATION <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;file:/tmp/checkpoint/</span><span style=color:#e6db74>{</span>QUERY_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>readstream_options <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;rowsPerSecond&#34;</span>: <span style=color:#e6db74>&#34;1&#34;</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>trigger_options <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;processingTime&#34;</span>: <span style=color:#e6db74>&#34;10 seconds&#34;</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>writestream_options <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;checkpointLocation&#34;</span>: CHECKPOINT_LOCATION,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>readstream_df: DataFrame <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>    spark
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>readStream
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>format(SOURCE)
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>options(<span style=color:#f92672>**</span>readstream_options)
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>load()
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>datastream_writer: DataStreamWriter <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>    readstream_df
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>writeStream
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>trigger(<span style=color:#f92672>**</span>trigger_options)
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>format(TARGET)
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>options(<span style=color:#f92672>**</span>writestream_options)
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>queryName(QUERY_NAME)
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>streaming_query: StreamingQuery <span style=color:#f92672>=</span> datastream_writer<span style=color:#f92672>.</span>start()
</span></span></code></pre></div><h3 id=streaming-query-listener---json-to-stdout>Streaming Query Listener - json to stdout<a hidden class=anchor aria-hidden=true href=#streaming-query-listener---json-to-stdout>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> datetime
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> json
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql.streaming.listener <span style=color:#f92672>import</span> (
</span></span><span style=display:flex><span>    QueryIdleEvent,
</span></span><span style=display:flex><span>    QueryProgressEvent,
</span></span><span style=display:flex><span>    QueryStartedEvent,
</span></span><span style=display:flex><span>    QueryTerminatedEvent,
</span></span><span style=display:flex><span>    StreamingQueryListener,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>StreamingQueryListenerJson</span>(StreamingQueryListener):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryStarted</span>(self, event: QueryStartedEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryStarted&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: event<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: event<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: event<span style=color:#f92672>.</span>runId,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;query started&#34;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        print(payload)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryProgress</span>(self, event: QueryProgressEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        json_data <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>loads(event<span style=color:#f92672>.</span>progress<span style=color:#f92672>.</span>json)
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryProgress&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: json_data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;id&#34;</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: json_data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;name&#34;</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: json_data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;runId&#34;</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: json<span style=color:#f92672>.</span>dumps(json_data)
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        print(payload)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryIdle</span>(self, event: QueryIdleEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryIdle&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: event<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: event<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: event<span style=color:#f92672>.</span>runId,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;query is idle&#34;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        print(payload)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryTerminated</span>(self, event: QueryTerminatedEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryIdle&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: event<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: event<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: event<span style=color:#f92672>.</span>runId,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;query is terminated&#34;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        print(payload)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spark<span style=color:#f92672>.</span>streams<span style=color:#f92672>.</span>addListener(StreamingQueryListenerJson())
</span></span></code></pre></div><h3 id=streaming-query-listener---json-to-a-file>Streaming Query Listener - json to a file<a hidden class=anchor aria-hidden=true href=#streaming-query-listener---json-to-a-file>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> datetime
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql.streaming.listener <span style=color:#f92672>import</span> (
</span></span><span style=display:flex><span>    QueryIdleEvent,
</span></span><span style=display:flex><span>    QueryProgressEvent,
</span></span><span style=display:flex><span>    QueryStartedEvent,
</span></span><span style=display:flex><span>    QueryTerminatedEvent,
</span></span><span style=display:flex><span>    StreamingQueryListener,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>StreamingQueryListenerJson</span>(StreamingQueryListener):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>f <span style=color:#f92672>=</span> open(<span style=color:#e6db74>&#34;/tmp/f.json&#34;</span>, <span style=color:#e6db74>&#34;w&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryStarted</span>(self, event: QueryStartedEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryStarted&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: event<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: event<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: event<span style=color:#f92672>.</span>runId,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;query started&#34;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>f<span style=color:#f92672>.</span>write(json<span style=color:#f92672>.</span>dumps(payload))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryProgress</span>(self, event: QueryProgressEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        json_data <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>loads(event<span style=color:#f92672>.</span>progress<span style=color:#f92672>.</span>json)
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryProgress&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: json_data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;id&#34;</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: json_data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;name&#34;</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: json_data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;runId&#34;</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: json<span style=color:#f92672>.</span>dumps(json_data)
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>f<span style=color:#f92672>.</span>write(json<span style=color:#f92672>.</span>dumps(payload))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryIdle</span>(self, event: QueryIdleEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryIdle&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: event<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: event<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: event<span style=color:#f92672>.</span>runId,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;query is idle&#34;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>f<span style=color:#f92672>.</span>write(json<span style=color:#f92672>.</span>dumps(payload))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryTerminated</span>(self, event: QueryTerminatedEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryIdle&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: event<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: event<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: event<span style=color:#f92672>.</span>runId,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;query is terminated&#34;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>f<span style=color:#f92672>.</span>write(json<span style=color:#f92672>.</span>dumps(payload))
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>f<span style=color:#f92672>.</span>close()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spark<span style=color:#f92672>.</span>streams<span style=color:#f92672>.</span>addListener(StreamingQueryListenerJson())
</span></span></code></pre></div><h3 id=streaming-query-listener---sqlite>Streaming Query Listener - Sqlite<a hidden class=anchor aria-hidden=true href=#streaming-query-listener---sqlite>#</a></h3><p>Sqlite is not multi-threaded so we can experience failures with concurrent writes. One way to prevent this issue from happening, is to append the <code>StreamingQueryListener</code> events to append to a Python <code>queue.Queue()</code> instead of directly to the database, so that all writes can be managed by a single thread.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> concurrent.futures <span style=color:#f92672>import</span> ThreadPoolExecutor
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> datetime
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> json
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> queue
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> sqlite3
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql.streaming.listener <span style=color:#f92672>import</span> (
</span></span><span style=display:flex><span>    QueryIdleEvent,
</span></span><span style=display:flex><span>    QueryProgressEvent,
</span></span><span style=display:flex><span>    QueryStartedEvent,
</span></span><span style=display:flex><span>    QueryTerminatedEvent,
</span></span><span style=display:flex><span>    StreamingQueryListener,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>DB_PATH <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;file:/tmp/f.db&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>StreamingQueryListenerSqlite</span>(StreamingQueryListener):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, db_path: str <span style=color:#f92672>=</span> DB_PATH) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>queue <span style=color:#f92672>=</span> queue<span style=color:#f92672>.</span>Queue()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>db_path <span style=color:#f92672>=</span> db_path
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_executor <span style=color:#f92672>=</span> ThreadPoolExecutor(max_workers<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_database_setup()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_insert_statement <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        INSERT INTO data
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            (time, event, id, name, runId, message)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            values (?, ?, ?, ?, ?, ?)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_executor<span style=color:#f92672>.</span>submit(self<span style=color:#f92672>.</span>_queue_worker)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_create_connection</span>(self) <span style=color:#f92672>-&gt;</span> sqlite3<span style=color:#f92672>.</span>Connection:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> sqlite3<span style=color:#f92672>.</span>connect(self<span style=color:#f92672>.</span>db_path)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_create_cursor</span>(self, connection: sqlite3<span style=color:#f92672>.</span>Connection) <span style=color:#f92672>-&gt;</span> sqlite3<span style=color:#f92672>.</span>Cursor:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> connection<span style=color:#f92672>.</span>cursor()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_database_setup</span>(self) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        conn <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_create_connection()
</span></span><span style=display:flex><span>        cur <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_create_cursor(connection<span style=color:#f92672>=</span>conn)
</span></span><span style=display:flex><span>        cur<span style=color:#f92672>.</span>execute(<span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        CREATE TABLE IF NOT EXISTS data (
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            time TIMESTAMP NOT NULL,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            event TEXT NOT NULL,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            id TEXT NOT NULL,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            name TEXT NOT NULL,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            runId TEXT NOT NULL,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            message TEXT NOT NULL
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        )
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>)
</span></span><span style=display:flex><span>        conn<span style=color:#f92672>.</span>commit()
</span></span><span style=display:flex><span>        conn<span style=color:#f92672>.</span>close()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryStarted</span>(self, event: QueryStartedEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryStarted&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: event<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: event<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: event<span style=color:#f92672>.</span>runId,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;query started&#34;</span>,
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>queue<span style=color:#f92672>.</span>put(json<span style=color:#f92672>.</span>dumps(payload))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryProgress</span>(self, event: QueryProgressEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        json_data <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>loads(event<span style=color:#f92672>.</span>progress<span style=color:#f92672>.</span>json)
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryProgress&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: json_data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;id&#34;</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: json_data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;name&#34;</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: json_data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;runId&#34;</span>),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: json<span style=color:#f92672>.</span>dumps(json_data),
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>queue<span style=color:#f92672>.</span>put(json<span style=color:#f92672>.</span>dumps(payload))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryIdle</span>(self, event: QueryIdleEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryIdle&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: event<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: event<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: event<span style=color:#f92672>.</span>runId,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;query is idle&#34;</span>,
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>queue<span style=color:#f92672>.</span>put(json<span style=color:#f92672>.</span>dumps(payload))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>onQueryTerminated</span>(self, event: QueryTerminatedEvent) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        payload <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;time&#34;</span>: datetime<span style=color:#f92672>.</span>datetime<span style=color:#f92672>.</span>now()<span style=color:#f92672>.</span>isoformat(),
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;event&#34;</span>: <span style=color:#e6db74>&#34;onQueryIdle&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;id&#34;</span>: event<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;name&#34;</span>: event<span style=color:#f92672>.</span>name,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;runId&#34;</span>: event<span style=color:#f92672>.</span>runId,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;query is terminated&#34;</span>,
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>queue<span style=color:#f92672>.</span>put(json<span style=color:#f92672>.</span>dumps(payload))
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_conn<span style=color:#f92672>.</span>close()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_queue_worker</span>(self) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;Background worker that processes items from the queue and inserts them into the database.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Runs continuously in a separate thread, polling the queue every second for new items.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        When an item is found, calls _insert_item_to_db to persist it.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        The worker will continue running until the thread is terminated or the program exits.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        If the queue is empty, it will wait for 1 second before checking again.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_conn <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_create_connection()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>_cursor <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_create_cursor(connection<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>_conn)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>                item: str <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>queue<span style=color:#f92672>.</span>get(timeout<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>_insert_item_to_db(
</span></span><span style=display:flex><span>                    item<span style=color:#f92672>=</span>item, connection<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>_conn, cursor<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>_cursor
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>except</span> queue<span style=color:#f92672>.</span>Empty:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>continue</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_insert_item_to_db</span>(
</span></span><span style=display:flex><span>        self, item: str, connection: sqlite3<span style=color:#f92672>.</span>Connection, cursor: sqlite3<span style=color:#f92672>.</span>Cursor
</span></span><span style=display:flex><span>    ) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;inserting item </span><span style=color:#e6db74>{</span>item<span style=color:#e6db74>}</span><span style=color:#e6db74> to db ...&#34;</span>)
</span></span><span style=display:flex><span>        data <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>loads(item)
</span></span><span style=display:flex><span>        cursor<span style=color:#f92672>.</span>execute(
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>_insert_statement,
</span></span><span style=display:flex><span>            (
</span></span><span style=display:flex><span>                data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;time&#34;</span>),
</span></span><span style=display:flex><span>                data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;event&#34;</span>),
</span></span><span style=display:flex><span>                data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;id&#34;</span>),
</span></span><span style=display:flex><span>                data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;name&#34;</span>),
</span></span><span style=display:flex><span>                data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;runId&#34;</span>),
</span></span><span style=display:flex><span>                data<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;message&#34;</span>),
</span></span><span style=display:flex><span>            ),
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        connection<span style=color:#f92672>.</span>commit()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spark<span style=color:#f92672>.</span>streams<span style=color:#f92672>.</span>addListener(StreamingQueryListenerSqlite())
</span></span></code></pre></div><h3 id=streaming-query-listener---other-options>Streaming Query Listener - other options<a hidden class=anchor aria-hidden=true href=#streaming-query-listener---other-options>#</a></h3><p>Other possible targets for the <code>StreamingQueryListener</code> events could include:</p><ul><li>an OLTP database like Postgres</li><li>DuckDB (although similar concurrency issues as experienced with Sqlite may occur)</li><li><a href=https://opentelemetry.io/>OpenTelemetry</a></li><li>AWS CloudWatch</li><li>Datadog / Splunk / Prometheus</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://be-rock.github.io/blog/tags/spark/>Spark</a></li><li><a href=https://be-rock.github.io/blog/tags/streaming/>Streaming</a></li><li><a href=https://be-rock.github.io/blog/tags/streaming-query-listener/>Streaming Query Listener</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://be-rock.github.io/blog/>Brock's Blog on Data|DevOps|Cloud</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>